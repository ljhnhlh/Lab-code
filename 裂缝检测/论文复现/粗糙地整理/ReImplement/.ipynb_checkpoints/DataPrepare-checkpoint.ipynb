{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先将crack像素坐标存在nzero_list中，no_crack像素坐标存于zero_list中\n",
    "其中，nzero_list shape为(118,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mat file :  ['001.mat', '002.mat', '003.mat', '004.mat', '005.mat', '006.mat', '007.mat', '008.mat', '009.mat', '010.mat', '011.mat', '012.mat', '013.mat', '014.mat', '015.mat', '016.mat', '017.mat', '018.mat', '019.mat', '020.mat', '021.mat', '022.mat', '023.mat', '024.mat', '025.mat', '026.mat', '027.mat', '028.mat', '029.mat', '030.mat', '031.mat', '032.mat', '033.mat', '034.mat', '035.mat', '036.mat', '037.mat', '038.mat', '039.mat', '040.mat', '041.mat', '042.mat', '043.mat', '044.mat', '045.mat', '046.mat', '047.mat', '048.mat', '049.mat', '050.mat', '051.mat', '052.mat', '053.mat', '054.mat', '055.mat', '056.mat', '057.mat', '058.mat', '059.mat', '060.mat', '061.mat', '062.mat', '063.mat', '064.mat', '065.mat', '066.mat', '067.mat', '068.mat', '069.mat', '070.mat', '071.mat', '072.mat', '073.mat', '074.mat', '075.mat', '076.mat', '077.mat', '078.mat', '079.mat', '080.mat', '081.mat', '082.mat', '083.mat', '084.mat', '085.mat', '086.mat', '087.mat', '088.mat', '089.mat', '090.mat', '091.mat', '092.mat', '093.mat', '094.mat', '095.mat', '096.mat', '097.mat', '098.mat', '099.mat', '100.mat', '101.mat', '102.mat', '103.mat', '104.mat', '105.mat', '106.mat', '107.mat', '108.mat', '109.mat', '110.mat', '111.mat', '112.mat', '113.mat', '114.mat', '115.mat', '116.mat', '117.mat', '118.mat']\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\\"\n",
    "\n",
    "\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "test = []\n",
    "def mat2csv():\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\")\n",
    "    if not os.path.exists(mat_data_path):\n",
    "        os.makedirs(mat_data_path)\n",
    "    file_list = os.listdir(mat_data_path)\n",
    "    mat_list = [file_name for file_name in file_list if file_name.endswith(\".mat\")]\n",
    "    print(\"find mat file : \", mat_list)\n",
    "    \n",
    "\n",
    "    for mat_file in mat_list:\n",
    "        file_path = os.path.join(mat_data_path, mat_file)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    test.append(dat)\n",
    "                    temp = dat - 1\n",
    "                    \n",
    "                    nzero_list.append(np.nonzero(temp))\n",
    "                    zero_list.append(np.argwhere(temp == 0))\n",
    "                    \n",
    "#                     print(dat[1][3])\n",
    "#                     print(dat.shape)\n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "        break;\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"text.csv\",test[0], delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取图片分割并写入本地"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切割正样本的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片路径及保存路径\n",
    "imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "imgSave = \"I:/1裂缝检测/CrackForest-dataset/trian/positive1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from PIL import Image\n",
    "def cut():\n",
    "    # 图片地址\n",
    "    temp = np.array(nzero_list)\n",
    "    for i in range(1):\n",
    "        i = i + 1\n",
    "        x_list = np.array(temp[i-1][1])\n",
    "        y_list = np.array(temp[i-1][0])\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        \n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str )\n",
    "        for j in range(len(x_list)):\n",
    "            x1 = x_list[j]-13\n",
    "            y1 = y_list[j]-13\n",
    "            x2 = x_list[j]+14\n",
    "            y2 = y_list[j]+14\n",
    "            im2 = im.crop((x1,y1,x2,y2))\n",
    "#             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "            im2.save(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n"
     ]
    }
   ],
   "source": [
    "cut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 剪切负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "imgSave = \"I:/1裂缝检测/CrackForest-dataset/trian/negative5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "def cut_negative():\n",
    "    # 图片地址\n",
    "    temp = np.array(zero_list)\n",
    "\n",
    "    for i in range(1):\n",
    "        i = i + 1\n",
    "        index_list = np.array(temp[i-1])\n",
    "#         str = sprintf(\"%3d\",i);\n",
    "#         str = str + \".jpg\"\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str)\n",
    "        for j in range(len(index_list)//27):\n",
    "            j = j * 20\n",
    "            if((index_list[j][1] > 27 and index_list[j][1] < 453)and (index_list[j][0] > 27 and index_list[j][0] < 293)):\n",
    "                x1 = index_list[j][1]-13\n",
    "                y1 = index_list[j][0]-13\n",
    "                x2 = index_list[j][1]+14\n",
    "                y2 = index_list[j][0]+14\n",
    "                im2 = im.crop((x1,y1,x2,y2))\n",
    "    #             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "                im2.save(imgSave+\"{:0>3d}{:0>7d}.jpg\".format(i,j))\n",
    "            \n",
    "#             j = j+27\n",
    "#             print(j)\n",
    "#             if(j+27 > len(index_list)):\n",
    "#                 break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n"
     ]
    }
   ],
   "source": [
    "cut_negative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移动样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil as sh \n",
    "\n",
    "positivePath = \"I:/1裂缝检测/CrackForest-dataset/train/pos/\"\n",
    "negativePath = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\train\\\\neg\\\\\"\n",
    "\n",
    "train_po_path = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\train\\\\data\\\\train\\\\crack\\\\\"\n",
    "train_ne_path = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\train\\\\data\\\\train\\\\no_crack\\\\\"\n",
    "\n",
    "val_po_path = \"I:/1裂缝检测/CrackForest-dataset/train/data/val/crack/\"\n",
    "val_ne_path = \"I:/1裂缝检测/CrackForest-dataset/train/data/val/no_crack/\"\n",
    "\n",
    "\n",
    "po_file_list = os.listdir(positivePath)\n",
    "ne_file_list = os.listdir(negativePath)\n",
    "# print(po_file_list)\n",
    "po_len = len(po_file_list)\n",
    "ne_len = len(ne_file_list)\n",
    "for j in range(len(po_file_list)):\n",
    "    if(j < po_len/3):\n",
    "        sh.move(positivePath+po_file_list[j],train_po_path+po_file_list[j])\n",
    "    else:\n",
    "        sh.move(positivePath+po_file_list[j],val_po_path+po_file_list[j])\n",
    "    if(j % 1000 == 0):\n",
    "        print(j)\n",
    "#     if(j > 20):\n",
    "#         break;\n",
    "\n",
    "for j in range(len(ne_file_list)):\n",
    "    if(j < ne_len/2):\n",
    "        sh.move(negativePath+ne_file_list[j],train_ne_path+ne_file_list[j])\n",
    "    else:\n",
    "        sh.move(negativePath+ne_file_list[j],val_ne_path+ne_file_list[j])\n",
    "#     if(j > 40):\n",
    "#         break\n",
    "    if(j % 1000 == 0):\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepare for detection \n",
    "以下代码可用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\001.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\002.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\003.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\004.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\005.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\006.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\007.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\008.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\009.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\010.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\011.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\012.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\013.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\014.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\015.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\016.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\017.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\018.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\019.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\020.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\021.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\022.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\023.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\024.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\025.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\026.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\027.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\028.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\029.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\030.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\031.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\032.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\033.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\034.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\035.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\036.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\037.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\038.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\039.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\040.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\041.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\042.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\043.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\044.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\045.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\046.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\047.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\048.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\049.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\050.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\051.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\052.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\053.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\054.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\055.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\056.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\057.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\058.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\059.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\060.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\061.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\062.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\063.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\064.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\065.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\066.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\067.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\068.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\069.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\070.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\071.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\072.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\073.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\074.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\075.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\076.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\077.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\078.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\079.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\080.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\081.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\082.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\083.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\084.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\085.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\086.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\087.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\088.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\089.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\090.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\091.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\092.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\093.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\094.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\095.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\096.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\097.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\098.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\099.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\100.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\101.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\102.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\103.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\104.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\105.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\106.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\107.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\108.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\109.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\110.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\111.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\112.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\113.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\114.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\115.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\116.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\117.mat\n",
      "I:\\1裂缝检测\\CrackForest-dataset\\groundTruth\\118.mat\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\\"\n",
    "\n",
    "\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "# 减1后，所有矩阵的数组\n",
    "all_matrix = []\n",
    "\n",
    "def mat2csv():\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\\\\\")\n",
    "\n",
    "    for i in range(1,119):\n",
    "        file_name= \"{:0>3d}.mat\".format(i)\n",
    "        file_path = mat_data_path+file_name\n",
    "        print(file_path)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    temp = dat - 1\n",
    "                    all_matrix.append(temp)\n",
    "                    nzero_list.append(np.nonzero(temp))\n",
    "                    zero_list.append(np.argwhere(temp == 0))\n",
    "                    \n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1831)\n",
      "414438\n"
     ]
    }
   ],
   "source": [
    "print(np.array(nzero_list[0]).shape)\n",
    "\n",
    "j = 0\n",
    "for x in nzero_list:\n",
    "    j += np.array(x).shape[1]\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151769, 2)\n",
      "17710362\n"
     ]
    }
   ],
   "source": [
    "print(np.array(zero_list[0]).shape)\n",
    "\n",
    "j = 0\n",
    "for x in zero_list:\n",
    "    j += np.array(x).shape[0]\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据两个对角的坐标切割图片\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "imgSave = \"I:/1裂缝检测/CrackForest-dataset/train/pos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "def cut_positive():\n",
    "    for i in range(118):\n",
    "        i = i + 1\n",
    "        one_matrix = np.array(all_matrix[i-1])\n",
    "        \n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str)\n",
    "        print(np.array(im).shape)\n",
    "        for i in range(0,480 - 27,2):\n",
    "            for j in range(0,320 - 27,5):\n",
    "#                 print(j)\n",
    "                temp = np.array(one_matrix[j:j+27,i:i+27])# x <= 320,y <= 480\n",
    "                \n",
    "                if(np.sum(temp) >= 50):\n",
    "                    im2 = im.crop((i,j,i+27,j+27))# ( x<=480,y <= 320 由上可知，temp[1][2],坐标为（2，1）)\n",
    "                    im2.save(imgSave+\"{:0>3d}{:0>7d}.jpg\".format(i,j))\n",
    "#                 j= j + 27\n",
    "            if(i%100 == 0):\n",
    "                print(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "002.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "003.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "004.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "005.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "006.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "007.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "008.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "009.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "010.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "011.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "012.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "013.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "014.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "015.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "016.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "017.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "018.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "019.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "020.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "021.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "022.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "023.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "024.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "025.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "026.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "027.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "028.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "029.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "030.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "031.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "032.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "033.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "034.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "035.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "036.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "037.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "038.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "039.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "040.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "041.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "042.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "043.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "044.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "045.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "046.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "047.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "048.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "049.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "050.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "051.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "052.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "053.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "054.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "055.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "056.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "057.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "058.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "059.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "060.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "061.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "062.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "063.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "064.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "065.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "066.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "067.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "068.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "069.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "070.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "071.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "072.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "073.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "074.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "075.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "076.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "077.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "078.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "079.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "080.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "081.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "082.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "083.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "084.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "085.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "086.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "087.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "088.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "089.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "090.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "091.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "092.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "093.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "094.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "095.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "096.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "097.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "098.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "099.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "100.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "101.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "102.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "103.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "104.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "105.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "106.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "107.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "108.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "109.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "110.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "111.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "112.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "113.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "114.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "115.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "116.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "117.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "118.jpg\n",
      "(320, 480, 3)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "cut_positive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "imgSave = \"I:/1裂缝检测/CrackForest-dataset/train/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "def cut_negative():\n",
    "    for i in range(118):\n",
    "        i = i + 1\n",
    "        one_matrix = np.array(all_matrix[i-1])\n",
    "        \n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str)\n",
    "        for i in range(0,480 - 27,2):\n",
    "            for j in range(0,320 - 27,4):\n",
    "                temp = np.array(one_matrix[j:j+27,i:i+27])\n",
    "                if(np.sum(temp) == 0):\n",
    "                    im2 = im.crop((i,j,i+27,j+27))\n",
    "                    im2.save(imgSave+\"{:0>3d}{:0>7d}.jpg\".format(i,j))\n",
    "            if(i%100 == 0):\n",
    "                print(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "002.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "003.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "004.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "005.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "006.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "007.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "008.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "009.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "010.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "011.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "012.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "013.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "014.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "015.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "016.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "017.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "018.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "019.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "020.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "021.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "022.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "023.jpg\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "cut_negative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据扩充\n",
    "对小图片扩充效果比较好\n",
    "大图片把不存在的像素用模糊的像素补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "190000\n",
      "191000\n",
      "192000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil as sh \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "path = [\"I:/1裂缝检测/CrackForest-dataset/train/data/train/crack/\",\"I:/1裂缝检测/CrackForest-dataset/train/data/val/crack/\"]\n",
    "\n",
    "for x in path:\n",
    "    file_list = os.listdir(x)\n",
    "    f = 0;\n",
    "    for y in file_list:\n",
    "        img = load_img(x+y)\n",
    "        temp = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        temp = temp.reshape((1,) + temp.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        i = 0\n",
    "        for batch in datagen.flow(temp, batch_size=1,\n",
    "                                  save_to_dir= x, save_prefix='dog', save_format='jpg'):\n",
    "            i += 1\n",
    "            f += 1\n",
    "            if i > 20:\n",
    "                break  # otherwise the generator would loop indefinitely\n",
    "#         break;\n",
    "            if(f % 1000 == 0):\n",
    "                print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
