{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class Crack(nn.Module):\n",
    "    def __init__(self, Crack_cfg):\n",
    "        super(Crack, self).__init__()\n",
    "        self.features = self._make_layers(Crack_cfg)\n",
    "        # linear layer\n",
    "#         self.classifier = nn.Linear(512, 10)\n",
    "#         self.linear1 = nn.Linear(32*6*6,64)\n",
    "#         self.linear2 = nn.Linear(64,64)\n",
    "#         self.linear3 = nn.Linear(64,25)\n",
    "        self.classifier = self.make_classifier()\n",
    "    \n",
    "    def make_classifier(self):\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(32*6*6,64),nn.ReLU(inplace=True),nn.Dropout(p=0.5)]\n",
    "        classifier += [nn.Linear(64,64),nn.ReLU(inplace=True),nn.Dropout(p=0.5)]\n",
    "        classifier += [nn.Linear(64,25)]\n",
    "        return nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "#         out = self.linear1(out)\n",
    "#         out = self.linear2(out)\n",
    "#         out = self.linear3(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        \"\"\"\n",
    "        cfg: a list define layers this layer contains\n",
    "            'M': MaxPool, number: Conv2d(out_channels=number) -> BN -> ReLU\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "            \n",
    "#         layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crack(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=64, out_features=25, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Crack_cfg = {\n",
    "    'Crack11':[16,16,'M',32,32,'M']\n",
    "}\n",
    "cracknet = Crack(Crack_cfg['Crack11']);\n",
    "print(cracknet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainloader,testloader,device,lr,optimizer,epoches):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optimizer;\n",
    "    running_loss = []\n",
    "    \n",
    "    running_accuracy = []\n",
    "    \n",
    "    temp_loss = 0.0\n",
    "    \n",
    "    # count the iteration number in an epoch\n",
    "    iteration = 0 \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        for i,data in enumerate(trainloader):\n",
    "            inputs,label = data\n",
    "            inputs,label = inputs.to(device),label.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = criterion(outputs,label)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            temp_loss += loss.item()\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, optimizer, device):\n",
    "    \"\"\"\n",
    "    train and evaluate an classifier num_epochs times.\n",
    "    We use optimizer and cross entropy loss to train the model. \n",
    "    Args: \n",
    "        model: CNN network\n",
    "        num_epochs: the number of training epochs\n",
    "        optimizer: optimize the loss function\n",
    "    \"\"\"\n",
    "        \n",
    "    # loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    # log train loss and test accuracy\n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}:'.format(epoch + 1, num_epochs))\n",
    "        # train step\n",
    "        loss = train(model, train_loader, loss_func, optimizer, device)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # evaluate step\n",
    "        accuracy = evaluate(model, test_loader, device)\n",
    "        accs.append(accuracy)\n",
    "        \n",
    "    \n",
    "    # show curve\n",
    "    show_curve(losses, \"train loss\")\n",
    "    show_curve(accs, \"test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    model: CNN networks\n",
    "    val_loader: a Dataloader object with validation data\n",
    "    device: evaluate on cpu or gpu device\n",
    "    return classification accuracy of the model on val dataset\n",
    "    \"\"\"\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            # device: cpu or gpu\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            \n",
    "            outputs = model(images)\n",
    "            print(outputs.numpy())\n",
    "            # return the maximum value of each row of the input tensor in the \n",
    "            # given dimension dim, the second return vale is the index location\n",
    "            # of each maxium value found(argmax)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on Test Set: {:.4f} %'.format(100 * accuracy))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_curve(ys, title):\n",
    "    \"\"\"\n",
    "    plot curlve for Loss and Accuacy\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: loss or accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} curve'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('{}'.format(title))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # mean and std of cifar10 in 3 channels \n",
    "# mean = (0.5,0.5,0.5)\n",
    "# std = (0.5,0.5,0.5)\n",
    "\n",
    "# # define transform operations of train dataset \n",
    "# data_transforms = {\n",
    "#     'train' = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)]),\n",
    "\n",
    "#     \"val\" = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)])\n",
    "# }\n",
    "\n",
    "\n",
    "# data_dir = 'I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\trian\\\\crack\\\\'\n",
    "\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           data_transforms[x])\t\n",
    "#                   for x in ['train', 'val']}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=100,\n",
    "#                                              shuffle=True)\n",
    "#               for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "# # Data loader: provides single- or multi-process iterators over the dataset.\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                            batch_size=256, \n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                           batch_size=256, \n",
    "#                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3752f4977c87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Device configuration, cpu, cuda:0/1/2/3 available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda:0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmycnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Device configuration, cpu, cuda:0/1/2/3 available\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "optimizer = torch.optim.Adam(mycnn.parameters(), lr=lr)\n",
    "\n",
    "# start training on cifar10 dataset\n",
    "fit(cracknet, num_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mat file :  ['001.mat', '002.mat', '003.mat', '004.mat', '005.mat', '006.mat', '007.mat', '008.mat', '009.mat', '010.mat', '011.mat', '012.mat', '013.mat', '014.mat', '015.mat', '016.mat', '017.mat', '018.mat', '019.mat', '020.mat', '021.mat', '022.mat', '023.mat', '024.mat', '025.mat', '026.mat', '027.mat', '028.mat', '029.mat', '030.mat', '031.mat', '032.mat', '033.mat', '034.mat', '035.mat', '036.mat', '037.mat', '038.mat', '039.mat', '040.mat', '041.mat', '042.mat', '043.mat', '044.mat', '045.mat', '046.mat', '047.mat', '048.mat', '049.mat', '050.mat', '051.mat', '052.mat', '053.mat', '054.mat', '055.mat', '056.mat', '057.mat', '058.mat', '059.mat', '060.mat', '061.mat', '062.mat', '063.mat', '064.mat', '065.mat', '066.mat', '067.mat', '068.mat', '069.mat', '070.mat', '071.mat', '072.mat', '073.mat', '074.mat', '075.mat', '076.mat', '077.mat', '078.mat', '079.mat', '080.mat', '081.mat', '082.mat', '083.mat', '084.mat', '085.mat', '086.mat', '087.mat', '088.mat', '089.mat', '090.mat', '091.mat', '092.mat', '093.mat', '094.mat', '095.mat', '096.mat', '097.mat', '098.mat', '099.mat', '100.mat', '101.mat', '102.mat', '103.mat', '104.mat', '105.mat', '106.mat', '107.mat', '108.mat', '109.mat', '110.mat', '111.mat', '112.mat', '113.mat', '114.mat', '115.mat', '116.mat', '117.mat', '118.mat']\n",
      "001.mat\n",
      "002.mat\n",
      "003.mat\n",
      "004.mat\n",
      "005.mat\n",
      "006.mat\n",
      "007.mat\n",
      "008.mat\n",
      "009.mat\n",
      "010.mat\n",
      "011.mat\n",
      "012.mat\n",
      "013.mat\n",
      "014.mat\n",
      "015.mat\n",
      "016.mat\n",
      "017.mat\n",
      "018.mat\n",
      "019.mat\n",
      "020.mat\n",
      "021.mat\n",
      "022.mat\n",
      "023.mat\n",
      "024.mat\n",
      "025.mat\n",
      "026.mat\n",
      "027.mat\n",
      "028.mat\n",
      "029.mat\n",
      "030.mat\n",
      "031.mat\n",
      "032.mat\n",
      "033.mat\n",
      "034.mat\n",
      "035.mat\n",
      "036.mat\n",
      "037.mat\n",
      "038.mat\n",
      "039.mat\n",
      "040.mat\n",
      "041.mat\n",
      "042.mat\n",
      "043.mat\n",
      "044.mat\n",
      "045.mat\n",
      "046.mat\n",
      "047.mat\n",
      "048.mat\n",
      "049.mat\n",
      "050.mat\n",
      "051.mat\n",
      "052.mat\n",
      "053.mat\n",
      "054.mat\n",
      "055.mat\n",
      "056.mat\n",
      "057.mat\n",
      "058.mat\n",
      "059.mat\n",
      "060.mat\n",
      "061.mat\n",
      "062.mat\n",
      "063.mat\n",
      "064.mat\n",
      "065.mat\n",
      "066.mat\n",
      "067.mat\n",
      "068.mat\n",
      "069.mat\n",
      "070.mat\n",
      "071.mat\n",
      "072.mat\n",
      "073.mat\n",
      "074.mat\n",
      "075.mat\n",
      "076.mat\n",
      "077.mat\n",
      "078.mat\n",
      "079.mat\n",
      "080.mat\n",
      "081.mat\n",
      "082.mat\n",
      "083.mat\n",
      "084.mat\n",
      "085.mat\n",
      "086.mat\n",
      "087.mat\n",
      "088.mat\n",
      "089.mat\n",
      "090.mat\n",
      "091.mat\n",
      "092.mat\n",
      "093.mat\n",
      "094.mat\n",
      "095.mat\n",
      "096.mat\n",
      "097.mat\n",
      "098.mat\n",
      "099.mat\n",
      "100.mat\n",
      "101.mat\n",
      "102.mat\n",
      "103.mat\n",
      "104.mat\n",
      "105.mat\n",
      "106.mat\n",
      "107.mat\n",
      "108.mat\n",
      "109.mat\n",
      "110.mat\n",
      "111.mat\n",
      "112.mat\n",
      "113.mat\n",
      "114.mat\n",
      "115.mat\n",
      "116.mat\n",
      "117.mat\n",
      "118.mat\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\\"\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "\n",
    "def mat2csv():\n",
    "\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\")\n",
    "#     csv_data_path = os.path.join(curr_path, \"csv\")\n",
    "#     if not os.path.exists(csv_data_path):\n",
    "#         os.makedirs(csv_data_path)\n",
    "    if not os.path.exists(mat_data_path):\n",
    "        os.makedirs(mat_data_path)\n",
    "    file_list = os.listdir(mat_data_path)\n",
    "    mat_list = [file_name for file_name in file_list if file_name.endswith(\".mat\")]\n",
    "    print(\"find mat file : \", mat_list)\n",
    "    \n",
    "\n",
    "    for mat_file in mat_list:\n",
    "        file_path = os.path.join(mat_data_path, mat_file)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                print (mat_file)\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    temp = dat - 1\n",
    "                    \n",
    "                    nzero_list.append(np.nonzero(temp))\n",
    "                    zero_list.append(np.argwhere(temp == 0))\n",
    "                    \n",
    "#                     print(dat[1][3])\n",
    "#                     print(dat.shape)\n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 2)\n"
     ]
    }
   ],
   "source": [
    "# print (point.shape())\n",
    "import numpy as np\n",
    "\n",
    "temp = np.array(nzero_list)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# path_di = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\\"\n",
    "# mat_data = sio.loadmat(path_di+\"groundTruth/005.mat\")\n",
    "\n",
    "# for key in mat_data:\n",
    "#             if not str(key).startswith(\"__\"):\n",
    "#                 data = mat_data[key][:]\n",
    "#                 try:\n",
    "#                     dat = np.array(data[0]['Segmentation'][0])\n",
    "#                     temp = dat - 1\n",
    "#                     plt.imshow(temp, cmap=plt.cm.gray, interpolation='nearest')\n",
    "#                 except ValueError as e:\n",
    "#                     print (e)\n",
    "#                     continue\n",
    "# # # print(mat_data)\n",
    "# # mat_data = np.array(mat_data[0])\n",
    "# # mat_data= mat_data-1\n",
    "# # plt.imshow(mat_data, cmap=plt.cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([101, 101, 102, ..., 319, 319, 319], dtype=int64), array([412, 413, 394, ...,  88, 146, 147], dtype=int64))\n",
      "313 413\n"
     ]
    }
   ],
   "source": [
    "print(nzero_list[1])\n",
    "x,y = nzero_list[:][0],nzero_list[:][1]\n",
    "# x = np.array(nzero_list[:][0])\n",
    "# y = np.array(nzero_list[:][1])\n",
    "print(x[1][1],y[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(temp[2][0])\n",
    "t = np.array(temp[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取图片分割并写入本地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 320)\n",
      "(320, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def test():\n",
    "    #读取一张图片，输出矩阵\n",
    "    imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "    im = Image.open(imgAddress+\"001.jpg\")\n",
    "    print(im.size)\n",
    "    arr = np.array(im)\n",
    "    print(arr.shape)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from PIL import Image\n",
    "def cut():\n",
    "    # 图片地址\n",
    "    temp = np.array(nzero_list)\n",
    "    imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "    imgSave = \"I:/1裂缝检测/CrackForest-dataset/trian/positive/\"\n",
    "    for i in range(118):\n",
    "        i = i + 1\n",
    "        x_list = np.array(temp[i-1][1])\n",
    "        y_list = np.array(temp[i-1][0])\n",
    "#         str = sprintf(\"%3d\",i);\n",
    "#         str = str + \".jpg\"\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        \n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str )\n",
    "        for j in range(len(x_list)):\n",
    "            x1 = x_list[j]-13\n",
    "            y1 = y_list[j]-13\n",
    "            x2 = x_list[j]+14\n",
    "            y2 = y_list[j]+14\n",
    "            im2 = im.crop((x1,y1,x2,y2))\n",
    "#             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "            im2.save(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 381\n"
     ]
    }
   ],
   "source": [
    "x_list = np.array(temp[1][0])\n",
    "y_list = np.array(temp[1][1])\n",
    "print(x_list[2376],y_list[2376])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集\n",
    "先别纠结了，直接将图片生成到本地，然后再导入处理\n",
    "下面是opencv剪切图片并保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n"
     ]
    }
   ],
   "source": [
    "cut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 剪切负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\\"\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "\n",
    "def mat2csv():\n",
    "\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\")\n",
    "    csv_data_path = os.path.join(curr_path, \"csv\")\n",
    "    if not os.path.exists(csv_data_path):\n",
    "        os.makedirs(csv_data_path)\n",
    "    if not os.path.exists(mat_data_path):\n",
    "        os.makedirs(mat_data_path)\n",
    "    file_list = os.listdir(mat_data_path)\n",
    "    mat_list = [file_name for file_name in file_list if file_name.endswith(\".mat\")]\n",
    "    print(\"find mat file : \", mat_list)\n",
    "    \n",
    "\n",
    "    for mat_file in mat_list:\n",
    "        file_path = os.path.join(mat_data_path, mat_file)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                print (mat_file)\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    temp = dat - 1\n",
    "                    \n",
    "                    nzero_list.append(np.nonzero(temp))\n",
    "                    zero_list.append(np.argwhere(temp == 0))\n",
    "                    \n",
    "#                     print(dat[1][3])\n",
    "#                     print(dat.shape)\n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(zero_list)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(zero_list)\n",
    "print(temp.shape)\n",
    "\n",
    "from PIL import Image\n",
    "def cut_negative():\n",
    "    # 图片地址\n",
    "    imgAddress = \"I:/1裂缝检测/CrackForest-dataset/image/\"\n",
    "    imgSave = \"I:/1裂缝检测/CrackForest-dataset/trian/negative4/\"\n",
    "    for i in range(118):\n",
    "        i = i + 1\n",
    "        index_list = np.array(temp[i-1])\n",
    "#         str = sprintf(\"%3d\",i);\n",
    "#         str = str + \".jpg\"\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str)\n",
    "        for j in range(len(index_list)//27):\n",
    "            j = j * 20\n",
    "            if((index_list[j][1] > 27 and index_list[j][1] < 453)and (index_list[j][0] > 27 and index_list[j][0] < 293)):\n",
    "                x1 = index_list[j][1]-13\n",
    "                y1 = index_list[j][0]-13\n",
    "                x2 = index_list[j][1]+14\n",
    "                y2 = index_list[j][0]+14\n",
    "                im2 = im.crop((x1,y1,x2,y2))\n",
    "    #             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "                im2.save(imgSave+\"{:0>3d}{:0>7d}.jpg\".format(i,j))\n",
    "            \n",
    "#             j = j+27\n",
    "#             print(j)\n",
    "#             if(j+27 > len(index_list)):\n",
    "#                 break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cut_negative' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-72ed1e5fdc3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcut_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cut_negative' is not defined"
     ]
    }
   ],
   "source": [
    "cut_negative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil as sh \n",
    "\n",
    "positivePath = \"I:/1裂缝检测/CrackForest-dataset/trian/positive/\"\n",
    "negativePath = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\trian\\\\negative4\\\\\"\n",
    "\n",
    "train_po_path = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\trian\\\\train2\\\\train\\\\crack\\\\\"\n",
    "train_ne_path = \"I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\trian\\\\train2\\\\train\\\\no_crack\\\\\"\n",
    "\n",
    "val_po_path = \"I:/1裂缝检测/CrackForest-dataset/trian/train2/val/crack/\"\n",
    "val_ne_path = \"I:/1裂缝检测/CrackForest-dataset/trian/train2/val/no_crack/\"\n",
    "\n",
    "\n",
    "po_file_list = os.listdir(positivePath)\n",
    "ne_file_list = os.listdir(negativePath)\n",
    "# print(po_file_list)\n",
    "\n",
    "for j in range(len(po_file_list)):\n",
    "    if(j < 1000):\n",
    "        sh.move(positivePath+po_file_list[j],train_po_path+po_file_list[j])\n",
    "    else:\n",
    "        sh.move(positivePath+po_file_list[j],val_po_path+po_file_list[j])\n",
    "    if(j % 1000 == 0):\n",
    "        print(j)\n",
    "    if(j > 2000):\n",
    "        break;\n",
    "\n",
    "for j in range(len(ne_file_list)):\n",
    "    if(j < 2000):\n",
    "        sh.move(negativePath+ne_file_list[j],train_ne_path+ne_file_list[j])\n",
    "    else:\n",
    "        sh.move(negativePath+ne_file_list[j],val_ne_path+ne_file_list[j])\n",
    "    if(j > 4000):\n",
    "        break\n",
    "    if(j % 1000 == 0):\n",
    "        print(j)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class Crack(nn.Module):\n",
    "    def __init__(self, Crack_cfg):\n",
    "        super(Crack, self).__init__()\n",
    "        self.features = self._make_layers(Crack_cfg)\n",
    "        # linear layer\n",
    "#         self.classifier = nn.Linear(512, 10)\n",
    "#         self.linear1 = nn.Linear(32*6*6,64)\n",
    "#         self.linear2 = nn.Linear(64,64)\n",
    "#         self.linear3 = nn.Linear(64,25)\n",
    "        self.classifier = self.make_classifier()\n",
    "    \n",
    "    def make_classifier(self):\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(32*6*6,64),nn.ReLU(inplace=True),nn.Dropout(p=0.5)]\n",
    "        classifier += [nn.Linear(64,64),nn.ReLU(inplace=True),nn.Dropout(p=0.5)]\n",
    "        classifier += [nn.Linear(64,2)]\n",
    "        return nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "#         out = self.linear1(out)\n",
    "#         out = self.linear2(out)\n",
    "#         out = self.linear3(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        \"\"\"\n",
    "        cfg: a list define layers this layer contains\n",
    "            'M': MaxPool, number: Conv2d(out_channels=number) -> BN -> ReLU\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "            \n",
    "#         layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crack(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crack_cfg = {\n",
    "    'Crack11':[16,16,'M',32,32,'M']\n",
    "}\n",
    "\n",
    "model_t = Crack(Crack_cfg['Crack11']);\n",
    "model_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0/19\n",
      "----------\n",
      "tensor(3272)\n",
      "tensor(3552)\n",
      "tensor(4000)\n",
      "train Loss: 0.2446 PRE: 0.9212 REC: 0.8180\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train' : transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]),\n",
    "    \"val\" : transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "}\n",
    "\n",
    "data_dir = 'I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\trian\\\\train2\\\\'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\t\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=256,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # 这里可能是使用了模型库里面的模型？！\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # best_acc = 0.0\n",
    "    best_pr = 0.0\n",
    "    best_re = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            L0 = 0\n",
    "            P0 = 0\n",
    "            P_neq = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #L0 = TP + FN,即原本的裂缝数据，包括真裂缝和假非裂缝\n",
    "                L0 += torch.sum(labels == 0)\n",
    "                #P0 = TP+FP ,即预测为裂缝的数据，包括真裂缝和假裂缝\n",
    "                P0 += torch.sum(preds == 0)\n",
    "                #P1 = FN+TN,即预测为非裂缝的数据，包括真非裂缝和假非裂缝\n",
    "                P_neq += torch.sum(preds != labels)\n",
    "            \n",
    "#             print(L0.numpy().size,P0.numpy().size,P1.numpy().size)\n",
    "            t = L0+P0-P_neq\n",
    "            print(t)\n",
    "            print(2*P0)\n",
    "            print(2*L0)\n",
    "            #经计算，TP = (L0+P0-P1)/2\n",
    "            #则PR = (L0+PO-P1)/(2*P0)\n",
    "            PRECISE = t.float()/(2*P0)\n",
    "            #RE = (L0+P0-P1)/(2*L0)，即原本的裂缝数据，有多少被检测出来了\n",
    "            RECALL = t.float()/(2*L0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} PRE: {:.4f} REC: {:.4f}'.format(\n",
    "                phase, epoch_loss, PRECISE,RECALL))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and (PRECISE >= best_pr or RECALL >= best_re):\n",
    "                best_re = RECALL\n",
    "                best_pr = PRECISE\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "  \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_re))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "    \n",
    "def train_model_25(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # 这里可能是使用了模型库里面的模型？！\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # best_acc = 0.0\n",
    "    best_pr = 0.0\n",
    "    best_re = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            L0 = 0\n",
    "            P0 = 0\n",
    "            P_neq = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "#                     print(outputs.data.numpy().shape)\n",
    "                    temp = np.array(outputs.data.numpy())\n",
    "#                     print(np.sum(t[0]),np.sum(t[20]))\n",
    "                    preds = []\n",
    "                    for x in temp:\n",
    "                        preds.append(np.sum(x))\n",
    "                    preds = np.array(preds)\n",
    "                    preds = (preds - np.min(preds))/(np.max(preds)-np.min(preds))\n",
    "                    preds[preds>= 0.5] = 1\n",
    "                    preds[preds < 0.5] = 0\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                labels = np.array(labels)\n",
    "                #L0 = TP + FN,即原本的裂缝数据，包括真裂缝和假非裂缝\n",
    "                L0 += np.sum(labels == 0)\n",
    "                \n",
    "                #P0 = TP+FP ,即预测为裂缝的数据，包括真裂缝和假裂缝\n",
    "                P0 += np.sum(preds == 0)\n",
    "                #P1 = FN+TN,即预测为非裂缝的数据，包括真非裂缝和假非裂缝\n",
    "                P_neq += np.sum(preds != labels)\n",
    "            \n",
    "#             print(L0.numpy().size,P0.numpy().size,P1.numpy().size)\n",
    "            t = L0+P0-P_neq\n",
    "            print(t)\n",
    "            print(2*P0)\n",
    "            print(2*L0)\n",
    "            #经计算，TP = (L0+P0-P1)/2\n",
    "            #则PR = (L0+PO-P1)/(2*P0)\n",
    "            PRECISE = t.float()/(2*P0)\n",
    "            #RE = (L0+P0-P1)/(2*L0)，即原本的裂缝数据，有多少被检测出来了\n",
    "            RECALL = t.float()/(2*L0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} PRE: {:.4f} REC: {:.4f}'.format(\n",
    "                phase, epoch_loss, PRECISE,RECALL))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and (PRECISE >= best_pr or RECALL >= best_re):\n",
    "                best_re = RECALL\n",
    "                best_pr = PRECISE\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "  \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_re))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    # fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "Crack_cfg = {\n",
    "    'Crack11':[16,16,'M',32,32,'M']\n",
    "}\n",
    "\n",
    "model_ft = Crack(Crack_cfg['Crack11']);\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs 退火\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)\n",
    "model_ft = model_ft.to('cpu')\n",
    "torch.save(model_ft.cpu().state_dict(),\"./crack.pt\")\n",
    "# # visualize_model(model_ft)\n",
    "# model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "# for param in model_conv.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# num_ftrs = model_conv.fc.in_features\n",
    "# model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# model_conv = model_conv.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Observe that only parameters of final layer are being optimized as\n",
    "# # opposed to before.\n",
    "# optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "# model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "#                          exp_lr_scheduler, num_epochs=25)\n",
    "# model_conv = model_conv.to('cpu')\n",
    "# torch.save(model_conv,\"./model1.pt\")\n",
    "# # visualize_model(model_conv)\n",
    "\n",
    "# # plt.ioff()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array(([1,0,0],[0,1,0],[1,0,1]))\n",
    "ff = np.array(([1,1,0],[0,0,0],[1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array(tt == ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False,  True]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.array(tt == 1)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-338395379d84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "g = np.arange(f == t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
