{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class Crack(nn.Module):\n",
    "    def __init__(self, Crack_cfg):\n",
    "        super(Crack, self).__init__()\n",
    "        self.features = self._make_layers(Crack_cfg)\n",
    "        # linear layer\n",
    "#         self.classifier = nn.Linear(512, 10)\n",
    "#         self.linear1 = nn.Linear(32*6*6,64)\n",
    "#         self.linear2 = nn.Linear(64,64)\n",
    "#         self.linear3 = nn.Linear(64,25)\n",
    "        self.classifier = self.make_classifier()\n",
    "    \n",
    "    def make_classifier(self):\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(32*6*6,64),nn.ReLU(inplace=True),nn.Dropout(p=0.5)]\n",
    "        classifier += [nn.Linear(64,64),nn.ReLU(inplace=True),nn.Dropout(p=0.5)]\n",
    "        classifier += [nn.Linear(64,25)]\n",
    "        return nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "#         out = self.linear1(out)\n",
    "#         out = self.linear2(out)\n",
    "#         out = self.linear3(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        \"\"\"\n",
    "        cfg: a list define layers this layer contains\n",
    "            'M': MaxPool, number: Conv2d(out_channels=number) -> BN -> ReLU\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "            \n",
    "#         layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crack(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=64, out_features=25, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Crack_cfg = {\n",
    "    'Crack11':[16,16,'M',32,32,'M']\n",
    "}\n",
    "cracknet = Crack(Crack_cfg['Crack11']);\n",
    "print(cracknet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainloader,testloader,device,lr,optimizer,epoches):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optimizer;\n",
    "    running_loss = []\n",
    "    \n",
    "    running_accuracy = []\n",
    "    \n",
    "    temp_loss = 0.0\n",
    "    \n",
    "    # count the iteration number in an epoch\n",
    "    iteration = 0 \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        for i,data in enumerate(trainloader):\n",
    "            inputs,label = data\n",
    "            inputs,label = inputs.to(device),label.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = criterion(outputs,label)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            temp_loss += loss.item()\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, optimizer, device):\n",
    "    \"\"\"\n",
    "    train and evaluate an classifier num_epochs times.\n",
    "    We use optimizer and cross entropy loss to train the model. \n",
    "    Args: \n",
    "        model: CNN network\n",
    "        num_epochs: the number of training epochs\n",
    "        optimizer: optimize the loss function\n",
    "    \"\"\"\n",
    "        \n",
    "    # loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    # log train loss and test accuracy\n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}:'.format(epoch + 1, num_epochs))\n",
    "        # train step\n",
    "        loss = train(model, train_loader, loss_func, optimizer, device)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # evaluate step\n",
    "        accuracy = evaluate(model, test_loader, device)\n",
    "        accs.append(accuracy)\n",
    "        \n",
    "    \n",
    "    # show curve\n",
    "    show_curve(losses, \"train loss\")\n",
    "    show_curve(accs, \"test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    model: CNN networks\n",
    "    val_loader: a Dataloader object with validation data\n",
    "    device: evaluate on cpu or gpu device\n",
    "    return classification accuracy of the model on val dataset\n",
    "    \"\"\"\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            # device: cpu or gpu\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # return the maximum value of each row of the input tensor in the \n",
    "            # given dimension dim, the second return vale is the index location\n",
    "            # of each maxium value found(argmax)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on Test Set: {:.4f} %'.format(100 * accuracy))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_curve(ys, title):\n",
    "    \"\"\"\n",
    "    plot curlve for Loss and Accuacy\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: loss or accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} curve'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('{}'.format(title))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # mean and std of cifar10 in 3 channels \n",
    "# mean = (0.5,0.5,0.5)\n",
    "# std = (0.5,0.5,0.5)\n",
    "\n",
    "# # define transform operations of train dataset \n",
    "# data_transforms = {\n",
    "#     'train' = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)]),\n",
    "\n",
    "#     \"val\" = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)])\n",
    "# }\n",
    "\n",
    "\n",
    "# data_dir = 'I:\\\\1裂缝检测\\\\CrackForest-dataset\\\\trian\\\\crack\\\\'\n",
    "\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           data_transforms[x])\t\n",
    "#                   for x in ['train', 'val']}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=100,\n",
    "#                                              shuffle=True)\n",
    "#               for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "# # Data loader: provides single- or multi-process iterators over the dataset.\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                            batch_size=256, \n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                           batch_size=256, \n",
    "#                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3752f4977c87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Device configuration, cpu, cuda:0/1/2/3 available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda:0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmycnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Device configuration, cpu, cuda:0/1/2/3 available\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "optimizer = torch.optim.Adam(mycnn.parameters(), lr=lr)\n",
    "\n",
    "# start training on cifar10 dataset\n",
    "fit(cracknet, num_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mat file :  ['071.mat', '038.mat', '093.mat', '087.mat', '026.mat', '085.mat', '013.mat', '039.mat', '012.mat', '105.mat', '106.mat', '080.mat', '024.mat', '048.mat', '007.mat', '077.mat', '023.mat', '084.mat', '016.mat', '075.mat', '059.mat', '076.mat', '103.mat', '086.mat', '035.mat', '031.mat', '058.mat', '027.mat', '010.mat', '047.mat', '065.mat', '046.mat', '101.mat', '022.mat', '074.mat', '056.mat', '112.mat', '115.mat', '082.mat', '067.mat', '060.mat', '095.mat', '055.mat', '102.mat', '104.mat', '062.mat', '079.mat', '005.mat', '018.mat', '044.mat', '100.mat', '042.mat', '030.mat', '094.mat', '072.mat', '092.mat', '032.mat', '096.mat', '091.mat', '109.mat', '111.mat', '066.mat', '019.mat', '006.mat', '081.mat', '028.mat', '001.mat', '033.mat', '108.mat', '052.mat', '021.mat', '041.mat', '017.mat', '011.mat', '043.mat', '051.mat', '097.mat', '064.mat', '089.mat', '088.mat', '037.mat', '073.mat', '090.mat', '116.mat', '002.mat', '118.mat', '099.mat', '008.mat', '061.mat', '003.mat', '107.mat', '069.mat', '054.mat', '034.mat', '063.mat', '029.mat', '014.mat', '078.mat', '045.mat', '098.mat', '040.mat', '057.mat', '053.mat', '113.mat', '036.mat', '110.mat', '009.mat', '025.mat', '015.mat', '050.mat', '049.mat', '083.mat', '070.mat', '020.mat', '068.mat', '117.mat', '004.mat', '114.mat']\n",
      "071.mat\n",
      "038.mat\n",
      "093.mat\n",
      "087.mat\n",
      "026.mat\n",
      "085.mat\n",
      "013.mat\n",
      "039.mat\n",
      "012.mat\n",
      "105.mat\n",
      "106.mat\n",
      "080.mat\n",
      "024.mat\n",
      "048.mat\n",
      "007.mat\n",
      "077.mat\n",
      "023.mat\n",
      "084.mat\n",
      "016.mat\n",
      "075.mat\n",
      "059.mat\n",
      "076.mat\n",
      "103.mat\n",
      "086.mat\n",
      "035.mat\n",
      "031.mat\n",
      "058.mat\n",
      "027.mat\n",
      "010.mat\n",
      "047.mat\n",
      "065.mat\n",
      "046.mat\n",
      "101.mat\n",
      "022.mat\n",
      "074.mat\n",
      "056.mat\n",
      "112.mat\n",
      "115.mat\n",
      "082.mat\n",
      "067.mat\n",
      "060.mat\n",
      "095.mat\n",
      "055.mat\n",
      "102.mat\n",
      "104.mat\n",
      "062.mat\n",
      "079.mat\n",
      "005.mat\n",
      "018.mat\n",
      "044.mat\n",
      "100.mat\n",
      "042.mat\n",
      "030.mat\n",
      "094.mat\n",
      "072.mat\n",
      "092.mat\n",
      "032.mat\n",
      "096.mat\n",
      "091.mat\n",
      "109.mat\n",
      "111.mat\n",
      "066.mat\n",
      "019.mat\n",
      "006.mat\n",
      "081.mat\n",
      "028.mat\n",
      "001.mat\n",
      "033.mat\n",
      "108.mat\n",
      "052.mat\n",
      "021.mat\n",
      "041.mat\n",
      "017.mat\n",
      "011.mat\n",
      "043.mat\n",
      "051.mat\n",
      "097.mat\n",
      "064.mat\n",
      "089.mat\n",
      "088.mat\n",
      "037.mat\n",
      "073.mat\n",
      "090.mat\n",
      "116.mat\n",
      "002.mat\n",
      "118.mat\n",
      "099.mat\n",
      "008.mat\n",
      "061.mat\n",
      "003.mat\n",
      "107.mat\n",
      "069.mat\n",
      "054.mat\n",
      "034.mat\n",
      "063.mat\n",
      "029.mat\n",
      "014.mat\n",
      "078.mat\n",
      "045.mat\n",
      "098.mat\n",
      "040.mat\n",
      "057.mat\n",
      "053.mat\n",
      "113.mat\n",
      "036.mat\n",
      "110.mat\n",
      "009.mat\n",
      "025.mat\n",
      "015.mat\n",
      "050.mat\n",
      "049.mat\n",
      "083.mat\n",
      "070.mat\n",
      "020.mat\n",
      "068.mat\n",
      "117.mat\n",
      "004.mat\n",
      "114.mat\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"./\"\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "\n",
    "def mat2csv():\n",
    "\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\")\n",
    "#     csv_data_path = os.path.join(curr_path, \"csv\")\n",
    "#     if not os.path.exists(csv_data_path):\n",
    "#         os.makedirs(csv_data_path)\n",
    "    if not os.path.exists(mat_data_path):\n",
    "        os.makedirs(mat_data_path)\n",
    "    file_list = os.listdir(mat_data_path)\n",
    "    mat_list = [file_name for file_name in file_list if file_name.endswith(\".mat\")]\n",
    "    print(\"find mat file : \", mat_list)\n",
    "    \n",
    "\n",
    "    for mat_file in mat_list:\n",
    "        file_path = os.path.join(mat_data_path, mat_file)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                print (mat_file)\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    temp = dat - 1\n",
    "                    \n",
    "                    nzero_list.append(np.nonzero(temp))\n",
    "                    zero_list.append(np.argwhere(temp == 0))\n",
    "                    \n",
    "#                     print(dat[1][3])\n",
    "#                     print(dat.shape)\n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 2)\n"
     ]
    }
   ],
   "source": [
    "# print (point.shape())\n",
    "import numpy as np\n",
    "\n",
    "temp = np.array(nzero_list)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 88,  89,  89, ..., 170, 170, 170]), array([  0,   0,   1, ..., 473, 474, 475]))\n"
     ]
    }
   ],
   "source": [
    "print(nzero_list[1])\n",
    "x,y = nzero_list[:][0],nzero_list[:][1]\n",
    "# x = np.array(nzero_list[:][0])\n",
    "# y = np.array(nzero_list[:][1])\n",
    "# print(x[1][1],y[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = np.array(temp[2][0])\n",
    "# t = np.array(temp[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取图片分割并写入本地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 320)\n",
      "(320, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def test():\n",
    "    #读取一张图片，输出矩阵\n",
    "    imgAddress = \"./image/\"\n",
    "    im = Image.open(imgAddress+\"001.jpg\")\n",
    "    print(im.size)\n",
    "    arr = np.array(im)\n",
    "    print(arr.shape)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from PIL import Image\n",
    "def cut():\n",
    "    # 图片地址\n",
    "    imgAddress = \"./image/\"\n",
    "    imgSave = \"./crack/\"\n",
    "    for i in range(1):\n",
    "        i = i + 1\n",
    "        x_list = np.array(temp[i-1][1])\n",
    "        y_list = np.array(temp[i-1][0])\n",
    "#         str = sprintf(\"%3d\",i);\n",
    "#         str = str + \".jpg\"\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        \n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str )\n",
    "        for j in range(len(x_list)):\n",
    "            x1 = x_list[j]-13\n",
    "            y1 = y_list[j]-13\n",
    "            x2 = x_list[j]+14\n",
    "            y2 = y_list[j]+14\n",
    "            im2 = im.crop((x1,y1,x2,y2))\n",
    "#             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "            im2.save(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4018 4018\n"
     ]
    }
   ],
   "source": [
    "x_list = np.array(temp[0][0])\n",
    "y_list = np.array(temp[0][1])\n",
    "# print(x_list[2376],y_list[2376])\n",
    "print(x_list.size,y_list.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集\n",
    "先别纠结了，直接将图片生成到本地，然后再导入处理\n",
    "下面是opencv剪切图片并保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n"
     ]
    }
   ],
   "source": [
    "cut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 剪切负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mat file :  ['071.mat', '038.mat', '093.mat', '087.mat', '026.mat', '085.mat', '013.mat', '039.mat', '012.mat', '105.mat', '106.mat', '080.mat', '024.mat', '048.mat', '007.mat', '077.mat', '023.mat', '084.mat', '016.mat', '075.mat', '059.mat', '076.mat', '103.mat', '086.mat', '035.mat', '031.mat', '058.mat', '027.mat', '010.mat', '047.mat', '065.mat', '046.mat', '101.mat', '022.mat', '074.mat', '056.mat', '112.mat', '115.mat', '082.mat', '067.mat', '060.mat', '095.mat', '055.mat', '102.mat', '104.mat', '062.mat', '079.mat', '005.mat', '018.mat', '044.mat', '100.mat', '042.mat', '030.mat', '094.mat', '072.mat', '092.mat', '032.mat', '096.mat', '091.mat', '109.mat', '111.mat', '066.mat', '019.mat', '006.mat', '081.mat', '028.mat', '001.mat', '033.mat', '108.mat', '052.mat', '021.mat', '041.mat', '017.mat', '011.mat', '043.mat', '051.mat', '097.mat', '064.mat', '089.mat', '088.mat', '037.mat', '073.mat', '090.mat', '116.mat', '002.mat', '118.mat', '099.mat', '008.mat', '061.mat', '003.mat', '107.mat', '069.mat', '054.mat', '034.mat', '063.mat', '029.mat', '014.mat', '078.mat', '045.mat', '098.mat', '040.mat', '057.mat', '053.mat', '113.mat', '036.mat', '110.mat', '009.mat', '025.mat', '015.mat', '050.mat', '049.mat', '083.mat', '070.mat', '020.mat', '068.mat', '117.mat', '004.mat', '114.mat']\n",
      "071.mat\n",
      "038.mat\n",
      "093.mat\n",
      "087.mat\n",
      "026.mat\n",
      "085.mat\n",
      "013.mat\n",
      "039.mat\n",
      "012.mat\n",
      "105.mat\n",
      "106.mat\n",
      "080.mat\n",
      "024.mat\n",
      "048.mat\n",
      "007.mat\n",
      "077.mat\n",
      "023.mat\n",
      "084.mat\n",
      "016.mat\n",
      "075.mat\n",
      "059.mat\n",
      "076.mat\n",
      "103.mat\n",
      "086.mat\n",
      "035.mat\n",
      "031.mat\n",
      "058.mat\n",
      "027.mat\n",
      "010.mat\n",
      "047.mat\n",
      "065.mat\n",
      "046.mat\n",
      "101.mat\n",
      "022.mat\n",
      "074.mat\n",
      "056.mat\n",
      "112.mat\n",
      "115.mat\n",
      "082.mat\n",
      "067.mat\n",
      "060.mat\n",
      "095.mat\n",
      "055.mat\n",
      "102.mat\n",
      "104.mat\n",
      "062.mat\n",
      "079.mat\n",
      "005.mat\n",
      "018.mat\n",
      "044.mat\n",
      "100.mat\n",
      "042.mat\n",
      "030.mat\n",
      "094.mat\n",
      "072.mat\n",
      "092.mat\n",
      "032.mat\n",
      "096.mat\n",
      "091.mat\n",
      "109.mat\n",
      "111.mat\n",
      "066.mat\n",
      "019.mat\n",
      "006.mat\n",
      "081.mat\n",
      "028.mat\n",
      "001.mat\n",
      "033.mat\n",
      "108.mat\n",
      "052.mat\n",
      "021.mat\n",
      "041.mat\n",
      "017.mat\n",
      "011.mat\n",
      "043.mat\n",
      "051.mat\n",
      "097.mat\n",
      "064.mat\n",
      "089.mat\n",
      "088.mat\n",
      "037.mat\n",
      "073.mat\n",
      "090.mat\n",
      "116.mat\n",
      "002.mat\n",
      "118.mat\n",
      "099.mat\n",
      "008.mat\n",
      "061.mat\n",
      "003.mat\n",
      "107.mat\n",
      "069.mat\n",
      "054.mat\n",
      "034.mat\n",
      "063.mat\n",
      "029.mat\n",
      "014.mat\n",
      "078.mat\n",
      "045.mat\n",
      "098.mat\n",
      "040.mat\n",
      "057.mat\n",
      "053.mat\n",
      "113.mat\n",
      "036.mat\n",
      "110.mat\n",
      "009.mat\n",
      "025.mat\n",
      "015.mat\n",
      "050.mat\n",
      "049.mat\n",
      "083.mat\n",
      "070.mat\n",
      "020.mat\n",
      "068.mat\n",
      "117.mat\n",
      "004.mat\n",
      "114.mat\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"./\"\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "\n",
    "def mat2csv():\n",
    "\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\")\n",
    "#     csv_data_path = os.path.join(curr_path, \"csv\")\n",
    "#     if not os.path.exists(csv_data_path):\n",
    "#         os.makedirs(csv_data_path)\n",
    "    if not os.path.exists(mat_data_path):\n",
    "        os.makedirs(mat_data_path)\n",
    "    file_list = os.listdir(mat_data_path)\n",
    "    mat_list = [file_name for file_name in file_list if file_name.endswith(\".mat\")]\n",
    "    print(\"find mat file : \", mat_list)\n",
    "    \n",
    "\n",
    "    for mat_file in mat_list:\n",
    "        file_path = os.path.join(mat_data_path, mat_file)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                print (mat_file)\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    temp = dat - 1\n",
    "                    nzero_list.append(np.argwhere(temp != 0))\n",
    "                    zero_list.append(np.argwhere(temp == 0))\n",
    "                    \n",
    "#                     print(dat[1][3])\n",
    "#                     print(dat.shape)\n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(zero_list)\n",
    "print(temp.shape)\n",
    "print(temp.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "t = np.array(nzero_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4018\n"
     ]
    }
   ],
   "source": [
    "t = np.array(t[0])\n",
    "print(t.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(zero_list)\n",
    "print(temp.shape)\n",
    "\n",
    "from PIL import Image\n",
    "def cut_negative():\n",
    "    # 图片地址\n",
    "    imgAddress = \"./image/\"\n",
    "    imgSave = \"./no_crack/\"\n",
    "    for i in range(1):\n",
    "        i = i + 1\n",
    "        index_list = np.array(temp[i-1])\n",
    "#         str = sprintf(\"%3d\",i);\n",
    "#         str = str + \".jpg\"\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str)\n",
    "        for j in range(len(index_list)//27):\n",
    "            j = j * 20\n",
    "            if((index_list[j][1] > 27 and index_list[j][1] < 453)and (index_list[j][0] > 27 and index_list[j][0] < 293)):\n",
    "                x1 = index_list[j][1]-13\n",
    "                y1 = index_list[j][0]-13\n",
    "                x2 = index_list[j][1]+14\n",
    "                y2 = index_list[j][0]+14\n",
    "                im2 = im.crop((x1,y1,x2,y2))\n",
    "    #             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "                im2.save(imgSave+\"{:0>3d}{:0>7d}.jpg\".format(i,j))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.jpg\n"
     ]
    }
   ],
   "source": [
    "cut_negative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 剪切正样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mat file :  ['071.mat', '038.mat', '093.mat', '087.mat', '026.mat', '085.mat', '013.mat', '039.mat', '012.mat', '105.mat', '106.mat', '080.mat', '024.mat', '048.mat', '007.mat', '077.mat', '023.mat', '084.mat', '016.mat', '075.mat', '059.mat', '076.mat', '103.mat', '086.mat', '035.mat', '031.mat', '058.mat', '027.mat', '010.mat', '047.mat', '065.mat', '046.mat', '101.mat', '022.mat', '074.mat', '056.mat', '112.mat', '115.mat', '082.mat', '067.mat', '060.mat', '095.mat', '055.mat', '102.mat', '104.mat', '062.mat', '079.mat', '005.mat', '018.mat', '044.mat', '100.mat', '042.mat', '030.mat', '094.mat', '072.mat', '092.mat', '032.mat', '096.mat', '091.mat', '109.mat', '111.mat', '066.mat', '019.mat', '006.mat', '081.mat', '028.mat', '001.mat', '033.mat', '108.mat', '052.mat', '021.mat', '041.mat', '017.mat', '011.mat', '043.mat', '051.mat', '097.mat', '064.mat', '089.mat', '088.mat', '037.mat', '073.mat', '090.mat', '116.mat', '002.mat', '118.mat', '099.mat', '008.mat', '061.mat', '003.mat', '107.mat', '069.mat', '054.mat', '034.mat', '063.mat', '029.mat', '014.mat', '078.mat', '045.mat', '098.mat', '040.mat', '057.mat', '053.mat', '113.mat', '036.mat', '110.mat', '009.mat', '025.mat', '015.mat', '050.mat', '049.mat', '083.mat', '070.mat', '020.mat', '068.mat', '117.mat', '004.mat', '114.mat']\n",
      "071.mat\n",
      "038.mat\n",
      "093.mat\n",
      "087.mat\n",
      "026.mat\n",
      "085.mat\n",
      "013.mat\n",
      "039.mat\n",
      "012.mat\n",
      "105.mat\n",
      "106.mat\n",
      "080.mat\n",
      "024.mat\n",
      "048.mat\n",
      "007.mat\n",
      "077.mat\n",
      "023.mat\n",
      "084.mat\n",
      "016.mat\n",
      "075.mat\n",
      "059.mat\n",
      "076.mat\n",
      "103.mat\n",
      "086.mat\n",
      "035.mat\n",
      "031.mat\n",
      "058.mat\n",
      "027.mat\n",
      "010.mat\n",
      "047.mat\n",
      "065.mat\n",
      "046.mat\n",
      "101.mat\n",
      "022.mat\n",
      "074.mat\n",
      "056.mat\n",
      "112.mat\n",
      "115.mat\n",
      "082.mat\n",
      "067.mat\n",
      "060.mat\n",
      "095.mat\n",
      "055.mat\n",
      "102.mat\n",
      "104.mat\n",
      "062.mat\n",
      "079.mat\n",
      "005.mat\n",
      "018.mat\n",
      "044.mat\n",
      "100.mat\n",
      "042.mat\n",
      "030.mat\n",
      "094.mat\n",
      "072.mat\n",
      "092.mat\n",
      "032.mat\n",
      "096.mat\n",
      "091.mat\n",
      "109.mat\n",
      "111.mat\n",
      "066.mat\n",
      "019.mat\n",
      "006.mat\n",
      "081.mat\n",
      "028.mat\n",
      "001.mat\n",
      "033.mat\n",
      "108.mat\n",
      "052.mat\n",
      "021.mat\n",
      "041.mat\n",
      "017.mat\n",
      "011.mat\n",
      "043.mat\n",
      "051.mat\n",
      "097.mat\n",
      "064.mat\n",
      "089.mat\n",
      "088.mat\n",
      "037.mat\n",
      "073.mat\n",
      "090.mat\n",
      "116.mat\n",
      "002.mat\n",
      "118.mat\n",
      "099.mat\n",
      "008.mat\n",
      "061.mat\n",
      "003.mat\n",
      "107.mat\n",
      "069.mat\n",
      "054.mat\n",
      "034.mat\n",
      "063.mat\n",
      "029.mat\n",
      "014.mat\n",
      "078.mat\n",
      "045.mat\n",
      "098.mat\n",
      "040.mat\n",
      "057.mat\n",
      "053.mat\n",
      "113.mat\n",
      "036.mat\n",
      "110.mat\n",
      "009.mat\n",
      "025.mat\n",
      "015.mat\n",
      "050.mat\n",
      "049.mat\n",
      "083.mat\n",
      "070.mat\n",
      "020.mat\n",
      "068.mat\n",
      "117.mat\n",
      "004.mat\n",
      "114.mat\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_dir = \"./\"\n",
    "\"\"\" 将path_dir 文件夹下的.mat 文件转成二元数组array\n",
    "因为该文件的数据较复杂：\n",
    "struct groundTruth {\n",
    "   Segmentation:320x480\n",
    "   Boundaries:320x480\n",
    "}  = loadmat(file_list)\n",
    "\n",
    "下面的结果是：\n",
    "dat[x][y] 就是 该320x480的某个值\n",
    "\n",
    "或许需要将其生成图片\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nzero_list = []\n",
    "zero_list = []\n",
    "\n",
    "def mat2csv():\n",
    "\n",
    "    curr_path = os.path.dirname(path_dir)\n",
    "    mat_data_path = os.path.join(curr_path, \"groundTruth\")\n",
    "    if not os.path.exists(mat_data_path):\n",
    "        os.makedirs(mat_data_path)\n",
    "    file_list = os.listdir(mat_data_path)\n",
    "    mat_list = [file_name for file_name in file_list if file_name.endswith(\".mat\")]\n",
    "    print(\"find mat file : \", mat_list)\n",
    "    \n",
    "\n",
    "    for mat_file in mat_list:\n",
    "        file_path = os.path.join(mat_data_path, mat_file)\n",
    "        mat_data = sio.loadmat(file_path)\n",
    "        for key in mat_data:\n",
    "            if not str(key).startswith(\"__\"):\n",
    "                data = mat_data[key][:]\n",
    "                print (mat_file)\n",
    "                try:\n",
    "                    dat = np.array(data[0]['Segmentation'][0])\n",
    "                    temp = dat - 1\n",
    "                    nzero_list.append(np.argwhere(temp != 0))\n",
    "                except ValueError as e:\n",
    "                    print (e)\n",
    "                    continue\n",
    "if __name__ == \"__main__\":\n",
    "    mat2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(nzero_list)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3678\n"
     ]
    }
   ],
   "source": [
    "tt = np.array(temp[13])\n",
    "print(tt.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(nzero_list)\n",
    "print(temp.shape)\n",
    "\n",
    "from PIL import Image\n",
    "def cut_positive():\n",
    "    # 图片地址\n",
    "    imgAddress = \"./image/\"\n",
    "    imgSave = \"./crack/\"\n",
    "    for i in range(1):\n",
    "        i = i + 10\n",
    "        index_list = np.array(temp[i-1])\n",
    "#         str = sprintf(\"%3d\",i);\n",
    "#         str = str + \".jpg\"\n",
    "        str = \"{:0>3d}.jpg\".format(i);\n",
    "        print(str)\n",
    "        im = Image.open(imgAddress + str)\n",
    "        for j in range(len(index_list)):\n",
    "            x1 = index_list[j][1]-13\n",
    "            y1 = index_list[j][0]-13\n",
    "            x2 = index_list[j][1]+14\n",
    "            y2 = index_list[j][0]+14\n",
    "            im2 = im.crop((x1,y1,x2,y2))\n",
    "    #             print(imgSave+\"{:0>3d}{:0>5d}.jpg\".format(i,j))\n",
    "            im2.save(imgSave+\"{:0>3d}{:0>7d}.jpg\".format(i,j))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010.jpg\n"
     ]
    }
   ],
   "source": [
    "cut_positive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil as sh \n",
    "\n",
    "positivePath = \"./crack/\"\n",
    "negativePath = \"./no_crack/\"\n",
    "\n",
    "train_po_path = \"./data/train/crack/\"\n",
    "train_ne_path = \"./data/train/no_crack/\"\n",
    "\n",
    "val_po_path = \"./data/val/crack/\"\n",
    "val_ne_path = \"./data/val/no_crack/\"\n",
    "\n",
    "\n",
    "po_file_list = os.listdir(positivePath)\n",
    "ne_file_list = os.listdir(negativePath)\n",
    "# print(po_file_list)\n",
    "\n",
    "for j in range(len(po_file_list)):\n",
    "    if(j < 100000):\n",
    "        sh.move(positivePath+po_file_list[j],train_po_path+po_file_list[j])\n",
    "    else:\n",
    "        sh.move(positivePath+po_file_list[j],val_po_path+po_file_list[j])\n",
    "    if(j % 10000 == 0):\n",
    "        print(j)\n",
    "#     if(j > 2000):\n",
    "#         break;\n",
    "\n",
    "for j in range(len(ne_file_list)):\n",
    "    if(j < 200000):\n",
    "        sh.move(negativePath+ne_file_list[j],train_ne_path+ne_file_list[j])\n",
    "    else:\n",
    "        sh.move(negativePath+ne_file_list[j],val_ne_path+ne_file_list[j])\n",
    "#     if(j > 4000):\n",
    "#         break\n",
    "    if(j % 1000 == 0):\n",
    "        print(j)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class Crack(nn.Module):\n",
    "    def __init__(self, Crack_cfg):\n",
    "        super(Crack, self).__init__()\n",
    "        self.features = self._make_layers(Crack_cfg)\n",
    "        # linear layer\n",
    "#         self.classifier = nn.Linear(512, 10)\n",
    "        self.linear1 = nn.Linear(32*6*6,64)\n",
    "#         self.linear1 = nn.Sequential([nn.Linear((32*6*6,64),\n",
    "#                                  nn.Sigmoid())])\n",
    "        self.linear2 = nn.Linear(64,64)\n",
    "#         self.linear2 = nn.Sequential([nn.Linear((64,64),\n",
    "#                                  nn.Sigmoid())])\n",
    "        self.linear3 = nn.Linear(64,2)\n",
    "#         self.linear3 = nn.Sequential([nn.Linear((64,25),\n",
    "#                                  nn.Sigmoid())])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "#         print(out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        \"\"\"\n",
    "        cfg: a list define layers this layer contains\n",
    "            'M': MaxPool, number: Conv2d(out_channels=number) -> BN -> ReLU\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "            \n",
    "#         layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crack(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (12): ReLU(inplace)\n",
       "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=64, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crack_cfg = {\n",
    "    'Crack11':[16,16,'M',32,32,'M']\n",
    "}\n",
    "\n",
    "model_t = Crack(Crack_cfg['Crack11']);\n",
    "model_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b0574d4b8930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train' : transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]),\n",
    "    \"val\" : transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "}\n",
    "\n",
    "data_dir = './data/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\t\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=256,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # 这里可能是使用了模型库里面的模型？！\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # best_acc = 0.0\n",
    "    best_pr = 0.0\n",
    "    best_re = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            L0 = 0\n",
    "            P0 = 0\n",
    "            P_neq = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                #L0 = TP + FN,即原本的裂缝数据，包括真裂缝和假非裂缝\n",
    "                L0 += torch.sum(labels == 0)\n",
    "                \n",
    "                #P0 = TP+FP ,即预测为裂缝的数据，包括真裂缝和假裂缝\n",
    "                P0 += torch.sum(preds == 0)\n",
    "                #P1 = FN+TN,即预测为非裂缝的数据，包括真非裂缝和假非裂缝\n",
    "                P_neq += torch.sum(preds != labels)\n",
    "            \n",
    "#             print(L0.numpy().size,P0.numpy().size,P1.numpy().size)\n",
    "            t = L0+P0-P_neq\n",
    "            print(t)\n",
    "            print(2*P0)\n",
    "            print(2*L0)\n",
    "            #经计算，TP = (L0+P0-P1)/2\n",
    "            #则PR = (L0+PO-P1)/(2*P0)\n",
    "            PRECISE = t.float()/(2*P0)\n",
    "            #RE = (L0+P0-P1)/(2*L0)，即原本的裂缝数据，有多少被检测出来了\n",
    "            RECALL = t.float()/(2*L0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} PRE: {:.4f} REC: {:.4f}'.format(\n",
    "                phase, epoch_loss, PRECISE,RECALL))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and (PRECISE >= best_pr or RECALL >= best_re):\n",
    "                best_re = RECALL\n",
    "                best_pr = PRECISE\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "  \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    # fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                # ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                # ax.axis('off')\n",
    "                # ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                # imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "Crack_cfg = {\n",
    "    'Crack11':[16,16,'M',32,32,'M']\n",
    "}\n",
    "\n",
    "model_ft = Crack(Crack_cfg['Crack11']);\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs 退火\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)\n",
    "model_ft = model_ft.to('cpu')\n",
    "torch.save(model_ft.cpu().state_dict(),\"./crack.pt\")\n",
    "# # visualize_model(model_ft)\n",
    "# model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "# for param in model_conv.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# num_ftrs = model_conv.fc.in_features\n",
    "# model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# model_conv = model_conv.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Observe that only parameters of final layer are being optimized as\n",
    "# # opposed to before.\n",
    "# optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "# model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "#                          exp_lr_scheduler, num_epochs=25)\n",
    "# model_conv = model_conv.to('cpu')\n",
    "# torch.save(model_conv,\"./model1.pt\")\n",
    "# # visualize_model(model_conv)\n",
    "\n",
    "# # plt.ioff()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7a3610b335f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gup\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"gup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array(([1,0,0],[0,1,0],[1,0,1]))\n",
    "ff = np.array(([1,1,0],[0,0,0],[1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array(tt == ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False,  True]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.array(tt == 1)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-338395379d84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "g = np.arange(f == t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
